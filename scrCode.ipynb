{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from urllib.parse import urljoin\n",
    "import time\n",
    "import csv\n",
    "import re\n",
    "\n",
    "def products_links(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # print(soup.prettify())\n",
    "\n",
    "    # Targeting the <ul> element with id \"product-grid\"\n",
    "    product_grid = soup.find('ul', id='product-grid')\n",
    "\n",
    "    # Targeting the <li> elements within the <ul> element\n",
    "    li_elements = product_grid.find_all('li')\n",
    "\n",
    "    # Extracting the links from the <li> elements and joining with the base URL\n",
    "    base_url = 'https://watchcollectors.co.uk'  # Replace with the actual base URL\n",
    "    all_product = [urljoin(base_url, li.find('a')['href']) for li in li_elements if li.find('a')]\n",
    "\n",
    "    return all_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress FutureWarnings for :contains\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"soupsieve\")\n",
    "\n",
    "imgUrls=[];productName=[];Price=[];modelNumber=[];modelYear=[];Gender=[];Diameter=[]\n",
    "originalBox=[];originalPaper=[];productUrls=[]\n",
    "\n",
    "def Product_details(links):\n",
    "    c = 0\n",
    "    for i in links:\n",
    "\n",
    "        response = requests.get(i)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        try:\n",
    "            image_urls = [img['data-src'] for img in soup.select('.media img[data-src]')]\n",
    "            imgUrls.append(image_urls)\n",
    "        except:\n",
    "            imgUrls.append('')\n",
    "\n",
    "        productUrls.append(i)\n",
    "        \n",
    "        try:\n",
    "            product_title = soup.select_one('.product__title').get_text(strip=True)\n",
    "            productName.append(product_title)\n",
    "\n",
    "        except:\n",
    "            productName.append('')\n",
    "            \n",
    "        try:\n",
    "            # price = soup.select_one('.price-item--regular').get_text(strip=True)\n",
    "            # Price.append(price)\n",
    "            price = soup.find(\"span\", class_=\"price-item price-item--regular\").text.strip().lstrip(\"£\")\n",
    "            # price = float(price.replace(\",\", \"\"))\n",
    "            Price.append(price)\n",
    "        except:\n",
    "            Price.append('')\n",
    "\n",
    "        \n",
    "        try:\n",
    "            model_number = soup.find('td', string='Model Number').find_next('td').get_text(strip=True)\n",
    "            modelNumber.append(model_number)\n",
    "            # # Find the <td> element with the text \"Model Number\"\n",
    "            # model_number_td = soup.find('td', string='Model Number')\n",
    "            # # If the <td> element is found, extract the model number from the following <td>\n",
    "            # if model_number_td:\n",
    "            #     model_number = model_number_td.find_next('td').get_text(strip=True)\n",
    "            # modelNumber.append(model_number)\n",
    "        except:\n",
    "            modelNumber.append('')\n",
    "    \n",
    "        try:\n",
    "            model_year = soup.find('td', string='Year').find_next('td').get_text(strip=True)\n",
    "            modelYear.append(model_year )\n",
    "        except:\n",
    "            modelYear.append('')\n",
    "    \n",
    "        try:\n",
    "            gender = soup.find('td', string='Gender').find_next('td').get_text(strip=True)\n",
    "            Gender.append(gender)\n",
    "        except:\n",
    "            Gender.append('')\n",
    "\n",
    "        try:\n",
    "            diameter = soup.find('td', string='Diameter (mm)').find_next('td').get_text(strip=True)\n",
    "            Diameter.append(diameter)\n",
    "        except:\n",
    "            Diameter.append('')\n",
    "\n",
    "        try:\n",
    "            original_box = soup.find('td', string='Original Box').find_next('td').get_text(strip=True)\n",
    "            originalBox.append(original_box)\n",
    "        except:\n",
    "            originalBox.append('')\n",
    "        \n",
    "        try:\n",
    "            original_papers = soup.find('td', string='Original Papers').find_next('td').get_text(strip=True)\n",
    "            originalPaper.append(original_papers)\n",
    "        except:\n",
    "            originalPaper.append('')\n",
    "        \n",
    "        c = c + 1\n",
    "        print(f\"Product {c} completed.\")\n",
    "\n",
    "        time.sleep(5)  # Sleep for 5 seconds between requests\n",
    "        \n",
    "        if c==2:\n",
    "            break\n",
    "        \n",
    "    # Writing to CSV file\n",
    "    with open('output.csv', 'w', encoding='utf-8', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Image Urls', 'Product Name', 'Price', 'Model Number', 'Model Year', 'Gender', 'Diameter',\n",
    "                        'Original Box', 'Original Papers', 'Product Url'])\n",
    "\n",
    "        for i in range(len(productName)):\n",
    "            # Join image URLs into a single string separated by commas\n",
    "            img_urls_str = ', '.join(imgUrls[i])\n",
    "            writer.writerow([img_urls_str, productName[i], Price[i], modelNumber[i], modelYear[i], Gender[i],\n",
    "                            Diameter[i], originalBox[i], originalPaper[i], productUrls[i]])\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# import csv\n",
    "# import time\n",
    "# import re\n",
    "# import warnings\n",
    "\n",
    "# # Suppress FutureWarnings for :contains\n",
    "# warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"soupsieve\")\n",
    "\n",
    "# imgUrls = []\n",
    "# productName = []\n",
    "# Price = []\n",
    "# modelNumber = []\n",
    "# modelYear = []\n",
    "# Gender = []\n",
    "# Diameter = []\n",
    "# originalBox = []\n",
    "# originalPaper = []\n",
    "# productUrls = []\n",
    "\n",
    "# def extract_price(soup):\n",
    "#     try:\n",
    "#         # Find all span elements that might contain the price\n",
    "#         price_elements = soup.find_all('span', class_='price-item')\n",
    "        \n",
    "#         # Iterate over the elements and look for the one containing the pound symbol\n",
    "#         for price_element in price_elements:\n",
    "#             price_text = price_element.get_text(strip=True)\n",
    "#             if '£' in price_text:\n",
    "#                 price_match = re.search(r'£([\\d,]+(\\.\\d{1,2})?)', price_text)\n",
    "#                 return price_match.group(1) if price_match else ''\n",
    "        \n",
    "#         return ''\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error extracting price: {e}\")\n",
    "#         return ''\n",
    "\n",
    "\n",
    "# def Product_details(links):\n",
    "#     c = 0\n",
    "#     for i in links:\n",
    "#         response = requests.get(i)\n",
    "#         soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "#         try:\n",
    "#             image_urls = [img['data-src'] for img in soup.select('.media img[data-src]')]\n",
    "#             imgUrls.append(image_urls)\n",
    "#         except:\n",
    "#             imgUrls.append('')\n",
    "\n",
    "#         productUrls.append(i)\n",
    "\n",
    "#         try:\n",
    "#             product_title = soup.select_one('.product__title').get_text(strip=True)\n",
    "#             productName.append(product_title)\n",
    "#         except:\n",
    "#             productName.append('')\n",
    "\n",
    "#         price = extract_price(soup)\n",
    "#         Price.append(price)\n",
    "\n",
    "#         try:\n",
    "#             model_number = soup.find('td', string='Model Number').find_next('td').get_text(strip=True)\n",
    "#             modelNumber.append(model_number)\n",
    "#         except:\n",
    "#             modelNumber.append('')\n",
    "\n",
    "#         try:\n",
    "#             model_year = soup.find('td', string='Year').find_next('td').get_text(strip=True)\n",
    "#             modelYear.append(model_year)\n",
    "#         except:\n",
    "#             modelYear.append('')\n",
    "\n",
    "#         try:\n",
    "#             gender = soup.find('td', string='Gender').find_next('td').get_text(strip=True)\n",
    "#             Gender.append(gender)\n",
    "#         except:\n",
    "#             Gender.append('')\n",
    "\n",
    "#         try:\n",
    "#             diameter = soup.find('td', string='Diameter (mm)').find_next('td').get_text(strip=True)\n",
    "#             Diameter.append(diameter)\n",
    "#         except:\n",
    "#             Diameter.append('')\n",
    "\n",
    "#         try:\n",
    "#             original_box = soup.find('td', string='Original Box').find_next('td').get_text(strip=True)\n",
    "#             originalBox.append(original_box)\n",
    "#         except:\n",
    "#             originalBox.append('')\n",
    "\n",
    "#         try:\n",
    "#             original_papers = soup.find('td', string='Original Papers').find_next('td').get_text(strip=True)\n",
    "#             originalPaper.append(original_papers)\n",
    "#         except:\n",
    "#             originalPaper.append('')\n",
    "\n",
    "#         c += 1\n",
    "#         print(f\"Product {c} completed.\")\n",
    "#         time.sleep(5)  # Sleep for 5 seconds between requests\n",
    "\n",
    "#         if c == 2:\n",
    "#             break\n",
    "\n",
    "#     # Writing to CSV file\n",
    "#     with open('output.csv', 'w', encoding='utf-8', newline='') as file:\n",
    "#         writer = csv.writer(file)\n",
    "#         writer.writerow(['Image Urls', 'Product Name', 'Price', 'Model Number', 'Model Year', 'Gender', 'Diameter',\n",
    "#                         'Original Box', 'Original Papers', 'Product Url'])\n",
    "\n",
    "#         for i in range(len(productName)):\n",
    "#             # Join image URLs into a single string separated by commas\n",
    "#             img_urls_str = ', '.join(imgUrls[i])\n",
    "#             writer.writerow([img_urls_str, productName[i], Price[i], modelNumber[i], modelYear[i], Gender[i],\n",
    "#                              Diameter[i], originalBox[i], originalPaper[i], productUrls[i]])\n",
    "#     return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://watchcollectors.co.uk/products/choaprd', 'https://watchcollectors.co.uk/products/louis-vuitton-ref-tambour-xl-minute-repeater-travel-time-18k-rose-gold-box-papers', 'https://watchcollectors.co.uk/products/rolex-lady-datejust-pearlmaster-ref-69298-white-mother-of-pearl-diamond-dial-18k-yellow-gold', 'https://watchcollectors.co.uk/products/rolex-yacht-master-40-ref-126622-slate-dial-box-papers-2021-stainless-steel-platinum', 'https://watchcollectors.co.uk/products/audemars-piguet-royal-oak-chronograph-ref-26603st-oo-d002cr-01000-blue-dial-box-papers-2010-stainless-steel', 'https://watchcollectors.co.uk/products/rolex-daytona-ref-116520-black-dial-2012-box-papers-stainless-steel-1', 'https://watchcollectors.co.uk/products/rolex-daytona-beach-blue-ref-116509-18k-white-gold-2007', 'https://watchcollectors.co.uk/products/vacheron-constantin-malte-chronograph-ref-49180-champagne-dial-40mm-18k-rose-gold', 'https://watchcollectors.co.uk/products/cartier-tank-americaine-chronograph-ref-2892-automatic-31mm-18k-yellow-gold', 'https://watchcollectors.co.uk/products/cartier-tank-americaine-chronograph-ref-3072-automatic-31mm-18k-rose-gold', 'https://watchcollectors.co.uk/products/cartier-tank-americaine-ref-2927-automatic-31mm-18k-rose-gold', 'https://watchcollectors.co.uk/products/cartier-tank-americaine-chronograph-ref-3073-automatic-31mm-18k-white-gold']\n"
     ]
    }
   ],
   "source": [
    "url = input(\"Enter Url: \")\n",
    "all_links = products_links(url)\n",
    "\n",
    "# Print the list of links\n",
    "print(all_links)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product 1 completed.\n",
      "Product 2 completed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Product_details(all_links)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
